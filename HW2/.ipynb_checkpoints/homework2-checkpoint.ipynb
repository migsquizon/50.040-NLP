{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JGpjwDsZWkhQ"
   },
   "source": [
    "# 50.040 Natural Language Processing (Summer 2020) Homework 2\n",
    "\n",
    "**Due**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XjOrxr6CWkhR"
   },
   "source": [
    "\n",
    "### STUDENT ID: 1003014\n",
    "\n",
    "### Name: Antonio Miguel Canlas Quizon\n",
    "\n",
    "### Students with whom you have discussed (if any):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "NuJaG1wnWrQr",
    "outputId": "42193fab-6c9a-45f9-c09a-24b41a3d8aa6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "fP8fpkNsWvFZ",
    "outputId": "46f2f076-098b-4e7b-e93e-b6c6538f7e5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mgdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n",
      "/content/gdrive/My Drive/NLP/HW2\n",
      "homework2.ipynb  hw2.pdf  \u001b[0m\u001b[01;34mimgs\u001b[0m/  \u001b[01;34m__MACOSX\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "% pwd\n",
    "% ls\n",
    "% cd /content/gdrive/'My Drive'/'NLP'/'HW2'\n",
    "% ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IAwvcZP5WkhS"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "from collections import Counter\n",
    "from nltk.tree import Tree\n",
    "from nltk import Nonterminal\n",
    "from nltk.corpus import LazyCorpusLoader, BracketParseCorpusReader\n",
    "from collections import defaultdict\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tj0zRY03WuYp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AQe-50jXWkhV"
   },
   "outputs": [],
   "source": [
    "st = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "gENuZm2iWkhX",
    "outputId": "a9ca0103-20a1-4824-ffc2-8bb40ca1f523"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('treebank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HZqhjuoUWkha"
   },
   "outputs": [],
   "source": [
    "def set_leave_lower(tree_string):\n",
    "    if isinstance(tree_string, Tree):\n",
    "        tree = tree_string\n",
    "    else:\n",
    "        tree = Tree.fromstring(tree_string)\n",
    "    for idx, _ in enumerate(tree.leaves()):\n",
    "        tree_location = tree.leaf_treeposition(idx)\n",
    "        non_terminal = tree[tree_location[:-1]]\n",
    "        non_terminal[0] = non_terminal[0].lower()\n",
    "    return tree\n",
    "\n",
    "def get_train_test_data():\n",
    "    '''\n",
    "    Load training and test set from nltk corpora\n",
    "    '''\n",
    "    train_num = 3900\n",
    "    test_index = range(10)\n",
    "    treebank = LazyCorpusLoader('treebank/combined', BracketParseCorpusReader, r'wsj_.*\\.mrg')\n",
    "    cnf_train = treebank.parsed_sents()[:train_num]\n",
    "    cnf_test = [treebank.parsed_sents()[i+train_num] for i in test_index]\n",
    "    #Convert to Chomsky norm form, remove auxiliary labels\n",
    "    cnf_train = [convert2cnf(t) for t in cnf_train]\n",
    "    cnf_test = [convert2cnf(t) for t in cnf_test]\n",
    "    return cnf_train, cnf_test\n",
    "def convert2cnf(original_tree):\n",
    "    '''\n",
    "    Chomsky norm form\n",
    "    '''\n",
    "    tree = copy.deepcopy(original_tree)\n",
    "    \n",
    "    #Remove cases like NP->DT, VP->NP\n",
    "    tree.collapse_unary(collapsePOS=True, collapseRoot=True)\n",
    "    #Convert to Chomsky\n",
    "    tree.chomsky_normal_form()\n",
    "    \n",
    "    tree = set_leave_lower(tree)\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w9QPZVvCWkhc"
   },
   "outputs": [],
   "source": [
    "### GET TRAIN/TEST DATA\n",
    "cnf_train, cnf_test = get_train_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "colab_type": "code",
    "id": "GnGcaxZhWkhe",
    "outputId": "b60818d0-86b1-4bcc-cf5f-c04257f68b92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP-SBJ\n",
      "    (NP (NNP pierre) (NNP vinken))\n",
      "    (NP-SBJ|<,-ADJP-,>\n",
      "      (, ,)\n",
      "      (NP-SBJ|<ADJP-,>\n",
      "        (ADJP (NP (CD 61) (NNS years)) (JJ old))\n",
      "        (, ,))))\n",
      "  (S|<VP-.>\n",
      "    (VP\n",
      "      (MD will)\n",
      "      (VP\n",
      "        (VB join)\n",
      "        (VP|<NP-PP-CLR-NP-TMP>\n",
      "          (NP (DT the) (NN board))\n",
      "          (VP|<PP-CLR-NP-TMP>\n",
      "            (PP-CLR\n",
      "              (IN as)\n",
      "              (NP\n",
      "                (DT a)\n",
      "                (NP|<JJ-NN> (JJ nonexecutive) (NN director))))\n",
      "            (NP-TMP (NNP nov.) (CD 29))))))\n",
      "    (. .)))\n"
     ]
    }
   ],
   "source": [
    "cnf_train[0].pprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q6ACIAJcWkhg"
   },
   "source": [
    "## Question 1\n",
    "\n",
    "To  better  understand  PCFG,  let’s  consider  the  first  parse  tree  in  the training data “cnf_train” as an example.  Run the code we have provided for you and then writedown the roles of.productions(), .rhs(), .lhs(), .leaves()in the ipynb notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "GjSPV0QAWkhg",
    "outputId": "9794c1dc-6413-4a38-fb3e-248b10c90bb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[S -> NP-SBJ S|<VP-.>, NP-SBJ -> NP NP-SBJ|<,-ADJP-,>, NP -> NNP NNP, NNP -> 'pierre', NNP -> 'vinken', NP-SBJ|<,-ADJP-,> -> , NP-SBJ|<ADJP-,>, , -> ',', NP-SBJ|<ADJP-,> -> ADJP ,, ADJP -> NP JJ, NP -> CD NNS, CD -> '61', NNS -> 'years', JJ -> 'old', , -> ',', S|<VP-.> -> VP ., VP -> MD VP, MD -> 'will', VP -> VB VP|<NP-PP-CLR-NP-TMP>, VB -> 'join', VP|<NP-PP-CLR-NP-TMP> -> NP VP|<PP-CLR-NP-TMP>, NP -> DT NN, DT -> 'the', NN -> 'board', VP|<PP-CLR-NP-TMP> -> PP-CLR NP-TMP, PP-CLR -> IN NP, IN -> 'as', NP -> DT NP|<JJ-NN>, DT -> 'a', NP|<JJ-NN> -> JJ NN, JJ -> 'nonexecutive', NN -> 'director', NP-TMP -> NNP CD, NNP -> 'nov.', CD -> '29', . -> '.'] <class 'nltk.grammar.Production'>\n"
     ]
    }
   ],
   "source": [
    "rules = cnf_train[0].productions()\n",
    "print(rules, type(rules[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Ll9ZEoBPWkhj",
    "outputId": "1f76890e-2628-4433-d106-effef83d0122"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('vinken',), nltk.grammar.Nonterminal)"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules[4].rhs(), type(rules[0].rhs()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "MSliPYXpWkhl",
    "outputId": "edec5486-65ca-46c3-85aa-6ea24a02b341"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('61',), str)"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules[10].rhs(), type(rules[10].rhs()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "1MfcsuX0Wkhn",
    "outputId": "42cd7955-2cba-4cb3-a7ba-2edfe3e85bed"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(S, nltk.grammar.Nonterminal)"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules[0].lhs(), type(rules[0].lhs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "EhSmFIpaWkhp",
    "outputId": "f964bc9c-3715-48c6-c2bb-6071c6cb8cea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pierre', 'vinken', ',', '61', 'years', 'old', ',', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'nov.', '29', '.']\n"
     ]
    }
   ],
   "source": [
    "print(cnf_train[0].leaves())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QgPkup85Wkhr"
   },
   "source": [
    "## ANSWER HERE\n",
    "- productions():  Returns the list of CFG rules that \"explain\" the tree. For each non-terminal node in the tree, tree.productions() will return a production with the parent node as LHS and the children as RHS.   \n",
    "\n",
    "- rhs(): Returns the right-hand side of a production - its children nodes\n",
    "- lhs(): Returns the left-hand side of a production - its parent node.\n",
    "- leaves(): Returns the leaves of a production - meaning the sentence formed using the set of rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8nU_vreyWkhs"
   },
   "source": [
    "## Question 2\n",
    "To count the number of unique rules, nonterminals and terminals, pleaseimplement functions **collect_rules, collect_nonterminals, collect_terminals**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kGAKj3WNWkhs"
   },
   "outputs": [],
   "source": [
    "def collect_rules(train_data):\n",
    "    '''\n",
    "    Collect the rules that appear in data.\n",
    "    params:\n",
    "        train_data: list[Tree] --- list of Tree objects\n",
    "    return:\n",
    "        rules: list[nltk.grammar.Production] --- list of rules (Production objects)\n",
    "        rules_counts: Counter object --- a dictionary that maps one rule (nltk.Nonterminal) to its number of \n",
    "                                         occurences (int) in train data.\n",
    "    '''\n",
    "    rules = list()\n",
    "    rules_counts = Counter()\n",
    "    ### YOUR CODE HERE (~ 2 lines)\n",
    "\n",
    "    # print(train_data[0].productions()\n",
    "    [[rules.append(prod) for prod in rule.productions()] for rule in train_data]\n",
    "    rules_counts = Counter(rules)\n",
    "    # print(rules_counts.most_common(5))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ### YOUR CODE HERE\n",
    "    return rules, rules_counts\n",
    "\n",
    "\n",
    "def collect_nonterminals(rules):\n",
    "    '''\n",
    "    collect nonterminals that appear in the rules\n",
    "    params:\n",
    "        rules: list[nltk.grammar.Production] --- list of rules (Production objects)\n",
    "    return:\n",
    "        nonterminals: set(nltk.Nonterminal) --- set of nonterminals \n",
    "    '''\n",
    "    nonterminals = list()\n",
    "    ### YOUR CODE HERE (at least one line)\n",
    "\n",
    "\n",
    "    for rule in rules:\n",
    "      nonterminals.append(rule.lhs())\n",
    "      for nonterm in rule.rhs():\n",
    "        if(isinstance(nonterm,str)):\n",
    "          continue\n",
    "        else:\n",
    "          nonterminals.append(nonterm)\n",
    "      \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ### END OF YOUR CODE\n",
    "    return set(nonterminals)\n",
    "    \n",
    "def collect_terminals(rules):\n",
    "    '''\n",
    "    collect terminals that appear in the rules\n",
    "    params:\n",
    "        rules: list[nltk.grammar.Production] --- list of rules (Production objects)\n",
    "    return:\n",
    "        terminals: set of strings --- set of terminals    \n",
    "    '''\n",
    "    terminals = list()\n",
    "    ### YOUR CODE HERE (at least one line)\n",
    "    # [[terminals.append(strings) for strings in rule.leaves()] for rule in rules]\n",
    "    # print(terminals[0])\n",
    "    # print(rules[0])\n",
    "    for rule in rules:\n",
    "      for term in rule.rhs():\n",
    "        if(isinstance(term,str)):\n",
    "          terminals.append(term)\n",
    "        else:\n",
    "          continue\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ### END OF YOUR CODE\n",
    "\n",
    "    return set(terminals)\n",
    "\n",
    "# terminals = collect_terminals(train_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nkiiN6DmWkhv"
   },
   "outputs": [],
   "source": [
    "train_rules, train_rules_counts = collect_rules(cnf_train)\n",
    "nonterminals = collect_nonterminals(train_rules)\n",
    "terminals = collect_terminals(train_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "EbuTPQaeWkhw",
    "outputId": "082b0922-d508-4c53-d9d1-a3598b8c992e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(196646, 31656, 11367, 7869)"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### CORRECT ANSWER (19xxxx, 3xxxx, 1xxxx, 7xxx)\n",
    "len(train_rules), len(set(train_rules)), len(terminals), len(nonterminals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "To760KR6Wkhy",
    "outputId": "8c702e35-26dc-48be-9883-afb321d51d61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(, -> ',', 4876), (DT -> 'the', 4726), (. -> '.', 3814), (PP -> IN NP, 3273), (S|<VP-.> -> VP ., 3003)]\n"
     ]
    }
   ],
   "source": [
    "print(train_rules_counts.most_common(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1vmpiFThWkh0"
   },
   "source": [
    "## Question 3\n",
    "Implement the function **build_pcfg** which builds a dictionary that stores the terminal rules and non-terminal rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AvoLJ2qCWkh1"
   },
   "outputs": [],
   "source": [
    "def build_pcfg(rules_counts):\n",
    "    '''\n",
    "    Build a dictionary that stores the terminal rules and nonterminal rules.\n",
    "    param:\n",
    "        rules_counts: Counter object --- a dictionary that maps one rule to its number of occurences in train data.\n",
    "    return:\n",
    "        rules_dict: dict(dict(dict)) --- a dictionary has a form like:\n",
    "                    rules_dict = {'terminals':{'NP':{'the':1000,'an':500}, 'ADJ':{'nice':500,'good':100}},\n",
    "                                  'nonterminals':{'S':{'NP@VP':1000},'NP':{'NP@NP':540}}}\n",
    "    When building \"rules_dict\", you need to use \"lhs()\", \"rhs()\" funtion and convert Nonterminal to str.\n",
    "    All the keys in the dictionary are of type str.\n",
    "    '@' is used as a special symbol to split left and right nonterminal strings.\n",
    "    '''\n",
    "    \n",
    "    rules_dict = dict()\n",
    "    ### rules_dict['terminals'] contains rules like \"NP->'the'\"\n",
    "    ### rules_dict['nonterminals'] contains rules like \"S->NP@VP\"\n",
    "    rules_dict['terminals'] = defaultdict(dict)\n",
    "    rules_dict['nonterminals'] = defaultdict(dict)\n",
    "    \n",
    "    ### YOUR CODE HERE\n",
    "\n",
    "    for rule in rules_counts:\n",
    "      s = '@'\n",
    "      temp_list = []\n",
    "\n",
    "      if len(rule.rhs())==1:\n",
    "          if isinstance(rule.rhs()[0],str):\n",
    "            rules_dict['terminals'][str(rule.lhs())][rule.rhs()[0]] = rules_counts[rule]\n",
    "\n",
    "      else:        \n",
    "        for child in rule.rhs():\n",
    "          temp_list.append(str(child))\n",
    "        s = s.join(temp_list)\n",
    "        # rules_dict['nonterminals'][str(rule.lhs())] = defaultdict(dict)\n",
    "        rules_dict['nonterminals'][str(rule.lhs())][s] = rules_counts[rule]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    ### END OF YOUR CODE\n",
    "    return rules_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "SjU2GthxWkh3",
    "outputId": "c520bc0b-fb85-4f00-c474-bbf1ee733372"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NP@JJ': 10, 'JJ@JJ': 8, 'JJ@S': 5, 'RB@JJ': 77, 'RB@VBN': 42, 'RB@JJR': 22, 'RB@DT': 2, 'JJ@PP': 42, 'CD@NN': 57, 'JJ@PRN': 1, 'QP@NN': 8, 'QP@-NONE-': 58, 'NP-ADV@JJR': 3, 'VBG@ADJP|<CC-VBG>': 1, 'RB@ADJP|<JJ-CC-JJ>': 2, 'ADJP@PP': 9, 'RB@ADJP|<RB-JJ>': 3, 'VBN@PP': 2, 'QP@JJR': 1, 'RBR@JJ': 22, '$@ADJP|<JJ--NONE->': 7, 'ADVP-TMP+RB@VBN': 1, 'CD@NNS': 1, 'RB@ADJP|<JJ-PP>': 6, 'RB@ADJP|<RB-JJ-PP>': 1, 'JJ@ADJP|<CD-NN>': 1, 'ADVP@JJ': 4, 'ADJP@ADJP|<,-ADJP-,-ADJP>': 1, 'ADVP-TMP@JJ': 1, 'RBS@JJ': 18, 'JJR@ADJP|<CC-JJR>': 2, '$@ADJP|<CD--NONE->': 28, 'ADVP-TMP+RB@ADJP|<RB-JJ>': 1, 'JJ@NP-TMP': 10, 'ADVP@VBN': 2, 'JJ@ADJP|<CC-JJ>': 18, 'JJ@ADJP|<CC-NNP>': 1, 'JJ@SBAR': 2, 'JJ@PP-LOC': 2, 'ADJP+JJ@ADJP|<,-CC-ADJP-,>': 1, 'NN@NN': 1, 'ADJP+JJ@ADJP|<CC-ADJP>': 1, 'RBS@ADJP|<RB-JJ>': 1, 'NNP@JJ': 6, 'JJ@ADJP|<,-JJ-CC-JJ>': 3, 'JJR@JJ': 4, 'NNS@ADJP|<CC-NNS>': 1, 'NNP@ADJP|<,-JJ>': 8, 'JJ@ADJP|<,-JJ-,-JJ-CC-NN>': 1, 'JJ@NP-TMP+CD': 11, 'NNP@NNP': 3, 'ADVP@ADJP|<JJ-PP>': 1, \"RB@ADJP|<``-JJ-CC-JJ-''>\": 1, 'RB@RB': 4, 'JJ@ADJP|<,-CC-JJ>': 1, 'ADJP@ADJP|<CC-ADJP>': 1, 'RB@ADJP|<VBN-PRT+RP-PP>': 1, 'JJS@JJ': 3, 'VBN@PP-CLR': 1, 'RB@ADJP|<JJ-PP-LOC>': 1, 'JJ@JJR': 1, 'JJ@ADJP|<CC-VBG>': 1, 'JJ@ADJP|<RB-SBAR+-NONE->': 1, 'NN@ADJP|<RB-SBAR+-NONE->': 1, 'QP@ADJP|<RB-JJ>': 1, 'ADVP-TMP+RB@JJ': 1, 'ADJP@ADJP|<,-CC-ADJP>': 1, 'RB@ADJP|<RB-PP-S>': 1, 'RB@ADJP|<RB-S>': 1, 'NN@JJ': 1, 'ADJP@ADJP|<CC-ADJP+JJ>': 2, 'RB@ADJP|<RBR-JJ>': 2, 'NNS@ADJP|<PRN-VBN>': 1, 'RB@ADJP|<JJR-IN>': 1, 'JJR@VBN': 1, 'RB@VBG': 2, 'RBS@VBN': 1, 'JJR@PP': 1, 'RBR@ADJP|<JJ-PP>': 1, 'ADVP+RB@ADJP|<RB-JJR>': 1, 'DT@ADJP|<ADJP+JJ-CC-ADJP+JJ>': 1, \"``@ADJP|<JJ-''-CC-``-JJ>\": 1, 'JJS@ADJP|<JJ-S>': 1, 'JJ@RB': 1, '$@ADJP|<CD-JJ>': 1, 'CD@ADJP|<CD-NN>': 8, 'JJ@PP-TMP': 2, 'JJ@JJS': 1, 'VB@JJR': 1, 'NP-ADV@JJ': 1, 'JJ@NP': 1, 'VBN@JJ': 1, 'NNP@ADJP|<NNP-,-JJ>': 1, 'ADJP+JJR@PP': 1, 'NN@ADJP|<CC-NN>': 1, '$@JJ': 1, \"``@ADJP|<RB-''-JJR>\": 1, 'JJ@ADJP|<CC-RB>': 1, 'CD@JJ': 1, 'IN@NN': 1, 'NP@ADJP|<JJ-PP>': 1, '``@ADJP|<RB-VBN>': 1, 'NNP@ADJP|<,-NNP-JJ>': 1, 'ADJP@ADJP|<CC-ADJP+JJR>': 1, 'JJ@VBN': 1, 'VBN@ADJP|<CC-JJ>': 1}\n"
     ]
    }
   ],
   "source": [
    "train_rules_dict = build_pcfg(train_rules_counts)\n",
    "print(train_rules_dict['nonterminals']['ADJP'])\n",
    "# print(train_rules_dict['nonterminals'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "zKBBcSWKT-TI",
    "outputId": "9d8f1a3d-d854-4f9f-b7f8-ecf22a3168c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NNP\n",
      ",\n",
      "CD\n",
      "NNS\n",
      "JJ\n",
      "MD\n",
      "VB\n",
      "DT\n",
      "NN\n",
      "IN\n",
      ".\n",
      "VBZ\n",
      "NP+NN\n",
      "VBG\n",
      "CC\n",
      "VBD\n",
      "VBN\n",
      "NP-SBJ+-NONE-\n",
      "ADVP-TMP+RB\n",
      "NP+-NONE-\n",
      "TO\n",
      "NP+NNS\n",
      "NP+PRP\n",
      "RBR\n",
      "NP-SBJ+NNS\n",
      "-NONE-\n",
      "S+-NONE-\n",
      "RB\n",
      "NP-SBJ+PRP\n",
      "WHNP-1+WDT\n",
      "VBP\n",
      "PRT+RP\n",
      "WHNP-2+WDT\n",
      "PRP$\n",
      "NP+CD\n",
      "JJS\n",
      "POS\n",
      "NP+NNP\n",
      "``\n",
      "NP-SBJ+DT\n",
      "NP-SBJ+NN\n",
      "NP-SBJ+EX\n",
      "''\n",
      "WHNP-3+WP\n",
      "NP-SBJ-1+NN\n",
      "WHNP-4+WP\n",
      "ADVP-MNR+RB\n",
      ":\n",
      "JJR\n",
      "NP+DT\n",
      "WHNP-5+WP\n",
      "NP-SBJ-4+-NONE-\n",
      "ADVP+RB\n",
      "WHNP-6+WP\n",
      "WHNP-7+WDT\n",
      "NP-SBJ-5+-NONE-\n",
      "ADJP-PRD+JJ\n",
      "WHNP-8+WDT\n",
      "SBAR+-NONE-\n",
      "WHADVP-1+WRB\n",
      "ADVP-LOC+-NONE-\n",
      "NP-SBJ-1+PRP\n",
      "NP-TMP+NN\n",
      "VP+VB\n",
      "NP-TMP+NNP\n",
      "NP-LGS+DT\n",
      "ADVP-DIR+RP\n",
      "NP-SBJ-1+NNS\n",
      "$\n",
      "ADVP-LOC+RB\n",
      "WHNP-9+WDT\n",
      "WHNP-10+WDT\n",
      "WHNP-11+WP\n",
      "VP+VBD\n",
      "NP-SBJ+NNP\n",
      "VP+VBZ\n",
      "WHNP-1+-NONE-\n",
      "NP+RB\n",
      "PP+-NONE-\n",
      "ADVP-TMP+-NONE-\n",
      "ADVP+JJR\n",
      "WHADVP-1+-NONE-\n",
      "PP-LOC-PRD+-NONE-\n",
      "WHADVP-3+WRB\n",
      "NP+JJR\n",
      "ADVP-CLR+RB\n",
      "NP-LOC+NNP\n",
      "WHNP-12+WDT\n",
      "NP-SBJ-1+NNP\n",
      "NP-SBJ-2+-NONE-\n",
      "NP-CLR+NN\n",
      "NP+JJ\n",
      "WHNP-13+WDT\n",
      "WHNP-1+WP\n",
      "WHNP-14+WP\n",
      "WHNP-15+WP\n",
      "NP-PRD+CD\n",
      "ADVP-DIR-CLR+IN\n",
      "WHNP+WDT\n",
      "PP-LOC+-NONE-\n",
      "WHNP-2+-NONE-\n",
      "WHNP-3+-NONE-\n",
      "NP-SBJ-14+NNP\n",
      "NP-SBJ-2+PRP\n",
      "NP-SBJ+WDT\n",
      "WHNP-16+WP\n",
      "WHNP-17+WDT\n",
      "NX+NN\n",
      "NNPS\n",
      "NP-2+-NONE-\n",
      "NP-SBJ-1+-NONE-\n",
      "NP-1+NNP\n",
      "ADVP+DT\n",
      "WHNP-18+WP\n",
      "WHNP-19+WP\n",
      "NP-PRD+NN\n",
      "WP$\n",
      "WHNP-1+IN\n",
      "WHNP-21+WDT\n",
      "ADVP-PRD-TPC-2+RB\n",
      "ADVP-PRD+-NONE-\n",
      "NP-SBJ-20+PRP\n",
      "WHNP-22+WDT\n",
      "NP-SBJ+IN\n",
      "NP-SBJ-21+-NONE-\n",
      "VP+-NONE-\n",
      "NP-SBJ-22+-NONE-\n",
      "WHNP-23+WDT\n",
      "WHNP-24+WDT\n",
      "WHNP-25+WDT\n",
      "ADVP-PRP+-NONE-\n",
      "NP-SBJ-24+-NONE-\n",
      "NP-SBJ-26+PRP\n",
      "WHNP-26+WDT\n",
      "NP-SBJ-3+-NONE-\n",
      "NX+NNS\n",
      "-LRB-\n",
      "-RRB-\n",
      "VP+VBG\n",
      "WHADVP-2+-NONE-\n",
      "ADVP-MNR+-NONE-\n",
      "NP-SBJ-2+NNP\n",
      "WHNP-27+WDT\n",
      "WHNP-28+WP\n",
      "WHNP-29+WP\n",
      "ADVP-TMP+IN\n",
      "PDT\n",
      "WHNP-30+WDT\n",
      "WHNP-31+WDT\n",
      "NP-SBJ-33+-NONE-\n",
      "ADJP+JJ\n",
      "ADJP-PRD+-NONE-\n",
      "ADVP-PRD-LOC+IN\n",
      "WHNP-32+WDT\n",
      "WHNP-33+WDT\n",
      "ADVP-LOC+JJ\n",
      "WHNP-34+WDT\n",
      "NP-SBJ-35+-NONE-\n",
      "WHNP-35+WDT\n",
      "NP+NNPS\n",
      "WHNP-36+WDT\n",
      "VP+JJ\n",
      "ADVP+JJ\n",
      "VP+VBP\n",
      "PP-TMP+-NONE-\n",
      "WHNP-37+WDT\n",
      "QP+RB\n",
      "WRB\n",
      "RP\n",
      "NP+RBS\n",
      "WHNP-38+WDT\n",
      "WHNP-39+WDT\n",
      "WHNP-40+WDT\n",
      "NP-1+NNS\n",
      "ADVP+RBR\n",
      "WHNP+WP\n",
      "NP-SBJ+JJ\n",
      "WHNP-42+WDT\n",
      "WHNP-43+WDT\n",
      "VP+VBN\n",
      "NP-SBJ-48+PRP\n",
      "WHNP-44+WDT\n",
      "WHNP-45+WP\n",
      "PRT+RBR\n",
      "NP-SBJ-52+-NONE-\n",
      "ADVP-PRD+RB\n",
      "WP\n",
      "ADVP-DIR+RB\n",
      "SBARQ+-NONE-\n",
      "ADVP-PRD-TPC-1+RB\n",
      "WHNP-47+WDT\n",
      "WHNP-48+WDT\n",
      "WHNP-49+WDT\n",
      "WHNP-50+WDT\n",
      "NP-SBJ-53+PRP\n",
      "NP-SBJ-54+PRP\n",
      "NP-SBJ-55+-NONE-\n",
      "ADJP+JJR\n",
      "NP-SBJ-2+NNS\n",
      "WHNP-51+WP\n",
      "NP+RBR\n",
      "NP-1+-NONE-\n",
      "ADVP-LOC-PRD-TPC-1+RB\n",
      "ADVP-LOC-PRD+-NONE-\n",
      "NP-PRD+NNP\n",
      "ADJP-PRD+VBG\n",
      "WHNP-52+WP\n",
      "WHNP-53+WP\n",
      "NP+JJS\n",
      "WHNP-55+WP\n",
      "WHNP-56+WP\n",
      "WHNP-57+WP\n",
      "PRP\n",
      "NP-SBJ-1+FW\n",
      "WHADVP+WRB\n",
      "WHNP-58+WP\n",
      "WHADVP-2+WRB\n",
      "RBS\n",
      "NP-SBJ-59+NNS\n",
      "NP-SBJ-4+NNP\n",
      "WHNP-59+WP\n",
      "NP-SBJ-60+NN\n",
      "WHNP-60+WDT\n",
      "WHNP-61+WP\n",
      "WHNP-62+WDT\n",
      "NP-SBJ-61+-NONE-\n",
      "NP-3+PRP\n",
      "WHNP-63+WP\n",
      "WHNP-64+WDT\n",
      "NP-TTL+-NONE-\n",
      "WHNP-65+WP\n",
      "WHNP-66+WP\n",
      "WHNP-67+WDT\n",
      "WHNP-2+WP\n",
      "ADJP+DT\n",
      "NP-SBJ-74+-NONE-\n",
      "NP-LGS+NNS\n",
      "WHNP-68+WP\n",
      "WHNP-69+WP\n",
      "WHNP-70+WDT\n",
      "WHNP-71+WP\n",
      "WHADVP-3+-NONE-\n",
      "WHNP-72+WDT\n",
      "WHNP-73+WDT\n",
      "WHNP-74+WDT\n",
      "FRAG+-NONE-\n",
      "WHNP-75+WDT\n",
      "FW\n",
      "NP-SBJ+NNPS\n",
      "WHNP-76+WDT\n",
      "WHNP-77+WP\n",
      "WHNP-78+WP\n",
      "NP-SBJ-3+PRP\n",
      "ADJP+VBN\n",
      "WHNP-2+IN\n",
      "ADJP-PRD+UH\n",
      "WHNP-79+WDT\n",
      "WHNP-80+WP\n",
      "WHNP-81+WP\n",
      "WHNP-82+WP\n",
      "WHNP-83+WP\n",
      "NP-3+-NONE-\n",
      "WHNP-84+WP\n",
      "NP-SBJ-1+JJS\n",
      "WHNP-85+WDT\n",
      "NP-SBJ-3+NNS\n",
      "PP-CLR+-NONE-\n",
      "WHNP-86+WDT\n",
      "WHNP-87+WP\n",
      "WHADVP-4+-NONE-\n",
      "NP-SBJ+CD\n",
      "WHNP-88+WDT\n",
      "WHNP-89+WP\n",
      "WHNP-3+IN\n",
      "WHNP-90+WP\n",
      "WHNP-91+WP\n",
      "ADJP-PRD+RB\n",
      "WHNP-92+WDT\n",
      "WHNP-93+WP\n",
      "WHNP-94+WP\n",
      "WHNP-95+WP\n",
      "WHNP-96+WP\n",
      "SQ+-NONE-\n",
      "WHNP-97+WP\n",
      "WHNP-98+WP\n",
      "ADVP-MNR+RBR\n",
      "NP-SBJ-2+NN\n",
      "WHNP-99+WDT\n",
      "WHNP-100+WP\n",
      "WHNP-101+WP\n",
      "NP-1+PRP\n",
      "WHNP-102+WP\n",
      "ADJP-PRD+JJR\n",
      "WHNP-103+WP\n",
      "WHNP-104+WDT\n",
      "WHNP-105+WDT\n",
      "NX-TTL+NNP\n",
      "WHNP-106+WDT\n",
      "WHNP-107+WDT\n",
      "WHNP-4+IN\n",
      "WHNP-108+WDT\n",
      "WHNP-109+WDT\n",
      "ADVP-TMP+RBR\n",
      "WHNP-110+WDT\n",
      "WHNP-111+WDT\n",
      "WHNP-112+WDT\n",
      "WHNP-113+WP\n",
      "NP-SBJ-3+EX\n",
      "WHNP-114+WDT\n",
      "WHNP-115+WDT\n",
      "WHNP-116+WDT\n",
      "NP-EXT+CD\n",
      "WHNP-117+WDT\n",
      "WHNP-118+WDT\n",
      "WHNP-119+WDT\n",
      "WHNP-120+WP\n",
      "NP+VB\n",
      "SBAR-LOC+-NONE-\n",
      "NP-ADV+DT\n",
      "WHNP-122+WDT\n",
      "WHNP-123+WP\n",
      "WHNP-124+WP\n",
      "WHNP-125+WP\n",
      "WHNP-126+WP\n",
      "WHNP-127+WP\n",
      "WHNP-128+WP\n",
      "WHNP-129+WP\n",
      "NP-ADV+PRP\n",
      "WHNP-130+WP\n",
      "WHNP-131+WP\n",
      "WHNP-132+WP\n",
      "WHNP-133+WDT\n",
      "WHNP-134+WDT\n",
      "NP-SBJ-2+DT\n",
      "WHNP-135+WP\n",
      "WHNP-136+WDT\n",
      "WHNP-137+WDT\n",
      "NP-4+-NONE-\n",
      "WHNP-138+WDT\n",
      "SYM\n",
      "WHNP-139+WDT\n",
      "WHNP-140+WDT\n",
      "WHNP-141+WDT\n",
      "WHNP-142+WDT\n",
      "WHNP-143+WDT\n",
      "WHNP-144+WDT\n",
      "X+IN\n",
      "LS\n",
      "WHNP-145+WDT\n",
      "NX+-NONE-\n",
      "PP-MNR+-NONE-\n",
      "WHNP-146+WDT\n",
      "ADVP-DIR+RBR\n",
      "WHNP-147+WDT\n",
      "WHNP-148+WDT\n",
      "NP-SBJ+JJS\n",
      "WHNP-149+WDT\n",
      "WHNP-150+WDT\n",
      "NP-TTL+NNP\n",
      "NP-2+NNS\n",
      "NP+VBG\n",
      "WHNP-152+WDT\n",
      "NP-TTL-SBJ+NNP\n",
      "NP-SBJ-78+PRP\n",
      "NP-PRD+-NONE-\n",
      "NP-TTL-SBJ-2+NNP\n",
      "WHNP-153+WDT\n",
      "NP-TTL-PRD+NNP\n",
      "WHNP-154+WDT\n",
      "NP-SBJ-85+-NONE-\n",
      "WHNP-155+WDT\n",
      "WHNP-156+WDT\n",
      "NP+WDT\n",
      "FRAG+ADJP-PRD+JJ\n",
      "ADVP+-NONE-\n",
      "NP-SBJ-91+-NONE-\n",
      "WHNP-157+WDT\n",
      "NP-SBJ-2+EX\n",
      "WHNP-158+WP\n",
      "VP+NN\n",
      "WHNP-159+WP\n",
      "WHNP-160+WP\n",
      "WHNP-161+WP\n",
      "NP-ADV+-NONE-\n",
      "WHNP-162+WDT\n",
      "NP-SBJ+RB\n",
      "WHNP-163+WDT\n",
      "WHNP-164+WP\n",
      "WHNP-165+WDT\n",
      "QP+-NONE-\n",
      "WHNP-166+WDT\n",
      "ADVP+NN\n",
      "NP-2+PRP\n",
      "INTJ+RB\n",
      "NP+IN\n",
      "NP-SBJ-98+PRP\n",
      "WHNP-167+WDT\n",
      "ADJP-PRD+VBN\n",
      "WHNP-168+WDT\n",
      "WHNP-169+WP\n",
      "ADVP-LOC-PRD+RB\n",
      "WHNP-170+WP\n",
      "WHNP-171+WP\n",
      "NP-SBJ-100+PRP\n",
      "WHNP-172+WP\n",
      "NP-SBJ-101+NN\n",
      "WHNP-3+WDT\n",
      "NP-TMP+CD\n",
      "WHNP-173+WDT\n",
      "WHNP-174+WDT\n",
      "WHNP-175+WDT\n",
      "ADVP-PRD+CD\n",
      "NP-CLR+NNS\n",
      "NP-SBJ-106+-NONE-\n",
      "WHNP-176+WDT\n",
      "WHNP-177+WDT\n",
      "WHADVP-2+IN\n",
      "NP-SBJ-107+-NONE-\n",
      "PP-CLR+IN\n",
      "NP-SBJ-108+-NONE-\n",
      "NP-SBJ-109+-NONE-\n",
      "NP-SBJ-110+-NONE-\n",
      "NP-SBJ-112+NNS\n",
      "WHNP-178+WP\n",
      "X+PP+IN\n",
      "WHNP-179+WDT\n",
      "NP-LGS+NNP\n",
      "WHNP-180+WDT\n",
      "WHNP-181+WP\n",
      "WHNP-182+WP\n",
      "ADVP-TMP+JJ\n",
      "WHNP-183+WP\n",
      "NP-SBJ-116+-NONE-\n",
      "WHNP-184+WP\n",
      "WHNP-185+WP\n",
      "PP-PRD+-NONE-\n",
      "WHNP-186+WDT\n",
      "WHNP-187+WP\n",
      "WHNP-189+WDT\n",
      "WHNP-190+WDT\n",
      "NP-SBJ-117+-NONE-\n",
      "WHNP-191+IN\n",
      "WHNP-192+WDT\n",
      "WHNP-193+WDT\n",
      "WHNP-194+WDT\n",
      "WHNP-195+WDT\n",
      "WHNP-196+WP\n",
      "NP-SBJ-4+PRP\n",
      "ADVP-MNR+IN\n",
      "WHNP-197+WDT\n",
      "WHNP-198+WDT\n",
      "WHNP-199+WDT\n",
      "WHNP-200+WDT\n",
      "WHNP-201+WP\n",
      "WHNP-202+WP\n",
      "WHNP-203+WP\n",
      "WHNP-204+WDT\n",
      "NP-SBJ-123+-NONE-\n",
      "WHNP-205+WDT\n",
      "WHNP-206+WP\n",
      "WHNP-207+WP\n",
      "WHNP-208+WDT\n",
      "ADVP+NNP\n",
      "WHNP-210+WDT\n",
      "NP-SBJ-127+-NONE-\n",
      "WHNP-211+WDT\n",
      "NP-SBJ-129+-NONE-\n",
      "WHNP-212+WDT\n",
      "WHNP-213+WDT\n",
      "WHNP-214+WP\n",
      "NP-SBJ+VBG\n",
      "WHNP-215+WDT\n",
      "NP-SBJ-131+-NONE-\n",
      "NP-SBJ-133+-NONE-\n",
      "WHNP-216+WP\n",
      "WHNP-217+WDT\n",
      "WHNP-218+WDT\n",
      "WHNP-219+WDT\n",
      "WHNP-220+WDT\n",
      "NP-SBJ-135+PRP\n",
      "WHNP-221+WP\n",
      "WHNP-222+WP\n",
      "WHNP-223+WDT\n",
      "WHNP-224+WDT\n",
      "WHNP-225+WDT\n",
      "WHNP-1+DT\n",
      "WHNP-226+WDT\n",
      "WHNP-227+WDT\n",
      "PP-LOC+RB\n",
      "WHNP-228+WP\n",
      "WHNP-229+WDT\n",
      "NP-SBJ-138+-NONE-\n",
      "ADVP-DIR-TPC-4+RB\n",
      "ADVP-DIR+-NONE-\n",
      "SINV+-NONE-\n",
      "NP-SBJ-140+-NONE-\n",
      "NP-PRD+NNS\n",
      "WHNP-230+WDT\n",
      "NP-SBJ-141+-NONE-\n",
      "WHNP-231+WDT\n",
      "ADVP-DIR+IN\n",
      "WHNP-232+WDT\n",
      "WHNP-233+WP\n",
      "ADJP+NN\n",
      "WHNP-234+WP\n",
      "ADVP+RP\n",
      "ADJP+-NONE-\n",
      "WHNP-235+WP\n",
      "NP-SBJ-144+-NONE-\n",
      "WHNP-236+WDT\n",
      "WHNP-237+WDT\n",
      "ADVP-CLR+-NONE-\n",
      "WHNP-238+WDT\n",
      "WHNP-239+WDT\n",
      "WHNP-240+WP\n",
      "WHNP-241+WDT\n",
      "WHNP-242+WP\n",
      "WHNP-243+WDT\n",
      "WHNP-244+WDT\n",
      "NP-SBJ-147+-NONE-\n",
      "WHNP-245+WDT\n",
      "PRT+IN\n",
      "ADVP-LOC-CLR+RB\n",
      "WHNP-246+WP\n",
      "ADVP-CLR+JJR\n",
      "WHNP-247+WP\n",
      "NP-SBJ-149+-NONE-\n",
      "NP+PRP$\n",
      "WHNP-248+WP\n",
      "NP-SBJ-1+CD\n",
      "NP-SBJ-151+CD\n",
      "WHNP-249+WP\n",
      "WHNP-250+WP\n",
      "WHNP-251+WDT\n",
      "WHADVP-4+WRB\n",
      "WHNP-252+WP\n",
      "NP-6+-NONE-\n",
      "NP-SBJ-159+PRP\n",
      "NX-1+NNS\n",
      "WHNP-253+WDT\n",
      "WHNP-254+WP\n",
      "WHNP-255+WDT\n",
      "WHNP-256+WP\n",
      "WHNP-257+WP\n",
      "WHNP+-NONE-\n",
      "WHNP-258+WDT\n",
      "#\n",
      "WHNP-259+WDT\n",
      "ADVP+PDT\n",
      "SBAR-ADV-3+-NONE-\n",
      "WHNP-260+WP\n",
      "NP-SBJ-165+-NONE-\n",
      "ADVP-MNR+JJ\n",
      "WHNP-6+WDT\n",
      "ADJP-PRD+JJS\n",
      "NP-SBJ-8+NNP\n",
      "WHNP-10+WP\n",
      "PP-DIR+-NONE-\n",
      "NP-SBJ-12+-NONE-\n",
      "NP-SBJ-13+-NONE-\n",
      "ADVP+IN\n",
      "ADVP-LOC+IN\n",
      "NP+FW\n",
      "WHNP-12+WP\n",
      "NP-SBJ-5+PRP\n",
      "INTJ+UH\n",
      "NP-SBJ-1+JJ\n",
      "WHNP-14+WDT\n",
      "NP-SBJ-16+PRP\n",
      "NP-SBJ-17+-NONE-\n",
      "NP-SBJ-18+-NONE-\n",
      "NP-SBJ-20+-NONE-\n",
      "WDT\n",
      "ADVP-LOC-CLR+-NONE-\n",
      "NP-SBJ-25+PRP\n",
      "NP-SBJ-27+NN\n",
      "NP-SBJ-28+PRP\n",
      "WHNP-19+WDT\n",
      "ADVP+CD\n",
      "WHNP-20+WP\n",
      "WHNP-21+WP\n",
      "NP-LGS+PRP\n",
      "NP-SBJ-31+PRP\n",
      "NP-SBJ-32+PRP\n",
      "NP-SBJ-34+-NONE-\n",
      "WHNP-24+WP\n",
      "NP-SBJ-36+-NONE-\n",
      "NP-PRD+DT\n",
      "WHNP-27+WP\n",
      "WHADVP-5+WRB\n",
      "NP-SBJ-39+-NONE-\n",
      "WHNP-28+WDT\n",
      "WHNP-30+WP\n",
      "WHNP-31+WP\n",
      "ADJP-PRD+NN\n",
      "WHNP-32+WP\n",
      "WHNP-33+WP\n",
      "WHNP-36+WP\n",
      "NP-SBJ-43+-NONE-\n",
      "WHNP-37+WP\n",
      "NP-SBJ-45+PRP\n",
      "WHNP-38+WP\n",
      "WHNP-39+WP\n",
      "NP-LGS+NN\n",
      "NP-SBJ-56+-NONE-\n",
      "WHNP-41+WDT\n",
      "NP-SBJ-58+-NONE-\n",
      "NP-2+NNP\n",
      "NP-SBJ-60+-NONE-\n",
      "PP+IN\n",
      "WHNP-42+WP\n",
      "WHNP-43+WP\n",
      "WHNP-45+WDT\n",
      "PRT+RB\n",
      "WHNP-46+WDT\n",
      "NP-SBJ-62+-NONE-\n",
      "WHNP-47+WP\n",
      "WHNP-48+WP\n",
      "NP-EXT+NNS\n",
      "NP-VOC+NNP\n",
      "WHNP-50+WP\n",
      "WHNP-49+WP\n",
      "WHNP-52+WDT\n",
      "WHNP-54+WP\n",
      "WHNP-56+WDT\n",
      "WHNP-57+WDT\n",
      "WHNP-61+WDT\n",
      "WHNP-64+WP\n",
      "PP-LOC-CLR+-NONE-\n",
      "NP-SBJ-71+-NONE-\n",
      "ADJP+RB\n",
      "WHNP-67+WP\n",
      "NP-PRD+JJR\n",
      "ADVP|PRT+RB\n",
      "ADVP-TMP+NN\n",
      "WHNP-72+WP\n",
      "WHNP-73+WP\n",
      "WHNP-75+WP\n",
      "NP-LOC+RB\n",
      "NP-SBJ+PRP$\n",
      "NP-SBJ-79+-NONE-\n",
      "ADJP-PRD+VB\n",
      "NP-VOC+NNS\n",
      "INTJ+VB\n",
      "NP-SBJ-80+-NONE-\n",
      "NP-SBJ-1+DT\n",
      "SBAR-ADV+-NONE-\n",
      "NP-SBJ-82+-NONE-\n",
      "WHNP-80+WDT\n",
      "NP-SBJ-83+-NONE-\n",
      "WHNP-81+WDT\n",
      "ADVP+JJS\n",
      "ADVP-TMP+JJR\n",
      "ADJP-PRD+VBD\n",
      "PRT+JJ\n",
      "ADVP-TMP-CLR+-NONE-\n",
      "WHNP+PRP\n",
      "S-ADV+-NONE-\n",
      "WHADVP+RB\n",
      "NP-ADV+NNP\n",
      "ADJP-PRD=1+JJR\n",
      "ADJP-PRD-1+VBN\n",
      "ADVP-LOC-PRD-1+RB\n",
      "NP-SBJ+JJR\n",
      "NP-SBJ+RBR\n",
      "ADJP-CLR+JJ\n",
      "LST+:\n",
      "WHNP-4+WDT\n",
      "S-PRP+-NONE-\n",
      "NP-TMP+-NONE-\n",
      "NP-HLN+NN\n",
      "FRAG+ADJP+JJ\n",
      "WHNP-5+WDT\n",
      "NP-SBJ-7+NNS\n",
      "ADJP-ADV+JJ\n",
      "NP-TMP-CLR+NN\n",
      "NP-3+NNP\n",
      "NP=3+NNP\n",
      "WHNP-4+-NONE-\n",
      "NP-ADV+NN\n",
      "ADVP-EXT+RB\n",
      "NP-TMP-CLR+CD\n",
      "NP-ADV+JJR\n",
      "NP-TMP-CLR+NNP\n",
      "WHNP-51+WDT\n",
      "NP-SBJ-3+NNP\n",
      "ADJP+RBR\n"
     ]
    }
   ],
   "source": [
    "for k in train_rules_dict['terminals'].keys():\n",
    "  if k not in train_rules_dict['nonterminals']:\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZrEiZvfDWkh5"
   },
   "source": [
    "## Question 4\n",
    "Estimate the probability of rule $NP\\rightarrow NNP@NNP$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ejl-xXiEWkh5",
    "outputId": "c1a27a92-252d-430d-8a3c-564399be04f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability of the rule is: 0.03950843529348353\n"
     ]
    }
   ],
   "source": [
    "np_count = 0\n",
    "for val in train_rules_dict['nonterminals']['NP'].values():\n",
    "  np_count += val\n",
    "# print(np_count)\n",
    "print(\"The probability of the rule is: \" + str(train_rules_dict['nonterminals']['NP']['NNP@NNP']/np_count))\n",
    "# prob = train_rules_dict['nonterminals'][NP]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EBNGNvo6Wkh7"
   },
   "source": [
    "## Question 5\n",
    "Find the terminal symbols in ''cnf_test[0]'' that never appeared in the PCFG we built. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "dpmfxNwfWkh7",
    "outputId": "2694239a-7484-4dbf-df1d-5d100f7fdb0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['constitutional-law']\n"
     ]
    }
   ],
   "source": [
    "# print(cnf_test[0].leaves())\n",
    "# for dic in train_rules_dict['terminals'].values():\n",
    "ret = cnf_test[0].leaves() \n",
    "for terminal in cnf_test[0].leaves():\n",
    "  for dic in train_rules_dict['terminals'].values():\n",
    "    # print(dic)\n",
    "    if terminal in dic:\n",
    "      try:\n",
    "        ret.remove(terminal)\n",
    "      except ValueError:\n",
    "        pass\n",
    "\n",
    "print(ret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o3NBdL8SWkh9"
   },
   "source": [
    "## Question 6\n",
    "We can use smoothing techniques to handle these cases. A simple smoothing method is as follows. We first create a new \"unknown\" terminal symbol $unk$.\n",
    "\n",
    "Next, for each original non-terminal symbol $A\\in N$, we add one new rule $A \\rightarrow unk$ to the original PCFG.\n",
    "\n",
    "The smoothed probabilities for all rules can then be estimated as:\n",
    "$$q_{smooth}(A \\rightarrow \\beta) = \\frac {count(A \\rightarrow \\beta)}{count(A)+1}$$\n",
    "$$q_{smooth}(A \\rightarrow unk) = \\frac {1}{count(A)+1}$$\n",
    "where $|V|$ is the count of unique terminal symbols.\n",
    "\n",
    "\n",
    "Implement the function **smooth_rules_prob** which returns the smoothed rule probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JFzfXUMJWkh-"
   },
   "outputs": [],
   "source": [
    "def smooth_rules_prob(rules_counts):\n",
    "    '''\n",
    "    params:\n",
    "        rules_counts: dict(dict(dict)) --- a dictionary has a form like:\n",
    "                      rules_counts = {'terminals':{'NP':{'the':1000,'an':500}, 'ADJ':{'nice':500,'good':100}},\n",
    "                                      'nonterminals':{'S':{'NP@VP':1000},'NP':{'NP@NP':540}}}\n",
    "    \n",
    "    return:\n",
    "        rules_prob: dict(dict(dict)) --- a dictionary that has a form like:\n",
    "                               rules_prob = {'terminals':{'NP':{'the':0.6,'an':0.3, '<unk>':0.1},\n",
    "                                                          'ADJ':{'nice':0.6,'good':0.3,'<unk>':0.1},\n",
    "                                                          'S':{'<unk>':0.01}}}\n",
    "                                             'nonterminals':{'S':{'NP@VP':0.99}}\n",
    "    '''\n",
    "    rules_prob = copy.deepcopy(rules_counts)\n",
    "    unk = '<unk>'\n",
    "    ### Hint: don't forget to consider nonterminal symbols that don't appear in rules_counts['terminals'].keys()\n",
    "    ### YOUR CODE HERE\n",
    "\n",
    "    for dic in rules_prob['terminals'].values():\n",
    "      total = 0\n",
    "      for val in dic.values():\n",
    "        total += val\n",
    "      for key,val in dic.items():\n",
    "        # print(key,val)\n",
    "        dic[key] = val/(total+1)\n",
    "      dic[unk] = 1/(total+1)\n",
    "      # print(dic[unk])\n",
    "    \n",
    "    for key,dic in rules_prob['nonterminals'].items():\n",
    "      total = 0\n",
    "      for val in dic.values():\n",
    "        total += val\n",
    "      for k,val in dic.items():\n",
    "        # print(key,val)\n",
    "        dic[k] = val/(total+1)\n",
    "      if key not in rules_prob['terminals']:\n",
    "        rules_prob['terminals'][key] = {unk:(1/(total+1))}\n",
    "\n",
    "\n",
    "    # for parent in set(list(rules_prob['terminals'].keys()) + list(rules_prob['nonterminals'].keys())):\n",
    "    #   total = 1\n",
    "    #   if parent in rules_prob['terminals'].keys():\n",
    "    #       total += sum(rules_prob['terminals'][parent].values())\n",
    "          \n",
    "    #   if parent in rules_prob['nonterminals'].keys():\n",
    "    #       total += sum(rules_prob['nonterminals'][parent].values())\n",
    "      \n",
    "      \n",
    "    #   if parent in rules_prob['terminals'].keys():\n",
    "    #       for child in rules_prob['terminals'][parent].keys():\n",
    "    #           rules_prob['terminals'][parent][child] /= total\n",
    "    #       rules_prob['terminals'][parent]['<unk>'] = 1/total\n",
    "          \n",
    "    #   if parent in rules_prob['nonterminals'].keys():\n",
    "    #       for child in rules_prob['nonterminals'][parent].keys():\n",
    "    #           rules_prob['nonterminals'][parent][child] /= total\n",
    "    #       if parent not in rules_prob['terminals']:\n",
    "    #           rules_prob['terminals'][parent]['<unk>'] = 1/total\n",
    "\n",
    "\n",
    "      \n",
    "    \n",
    "        \n",
    "      \n",
    "\n",
    "\n",
    "    ### END OF YOUR CODE\n",
    "    return rules_prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T3cLUHnMWkh_"
   },
   "outputs": [],
   "source": [
    "s_rules_prob = smooth_rules_prob(train_rules_dict)\n",
    "terminals.add('<unk>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "C0k7my2gWkiB",
    "outputId": "0cc99b78-b25a-4443-87aa-33aef18d50fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1300172371337109\n",
      "0.025240088648116228\n",
      "0.039506305917861376\n",
      "{'<unk>': 5.389673385792821e-05}\n"
     ]
    }
   ],
   "source": [
    "print(s_rules_prob['nonterminals']['S']['NP-SBJ@S|<VP-.>'])\n",
    "print(s_rules_prob['nonterminals']['S']['NP-SBJ-1@S|<VP-.>'])\n",
    "print(s_rules_prob['nonterminals']['NP']['NNP@NNP'])\n",
    "print(s_rules_prob['terminals']['NP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qVkbPHz-WkiD",
    "outputId": "fde16cca-c357-4b37-af58-6c7e7bb76dfd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11368"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(terminals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8tt6OQ6OWkiF"
   },
   "source": [
    "## CKY Algorithm\n",
    "\n",
    "Similar to the Viterbi algorithm, the CKY algorithm is a dynamic-programming algorithm. Given a PCFG $G=(N, \\ \\Sigma, \\ S, \\ R, \\ q)$, we can use the CKY algorithm described in class to find the highest scoring parse tree for a sentence. \n",
    "\n",
    "First, let us complete the *CKY* function from scratch using only Python built-in functions and the Numpy package. \n",
    "\n",
    "The output should be two dictionaries $\\pi$ and $bp$, which store the optimal probability and backpointer information respectively.\n",
    "\n",
    "Given a sentence $w_0, w_1, ...,w_{n-1}$,  $\\pi(i, k, X)$, $bp(i, k, X)$ refer to the highest score and backpointer for the (partial) parse tree that has the root X (a non-terminal symbol) and covers the word span $w_i, ..., w_{k-1}$, where $0 \\le i < k \\le n$. Note that a backpointer includes both the best grammar rule chosen and the best split point.\n",
    "![tree](imgs/parse_tree.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c4RYXO2KWkiF"
   },
   "source": [
    "## Question 7\n",
    "Implement **CKY** function and run the test code to check your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "kjRTxt4NWkiH",
    "outputId": "c5bf31cc-fd22-4884-d10d-4abc77b43aab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-117.52227496068694\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "def CKY(sent, rules_prob):\n",
    "    '''\n",
    "    params:\n",
    "        sent: list[str] --- a list of strings\n",
    "        rules_prob: dict(dict(dict)) --- a dictionary that has a form like:\n",
    "                                           rules_prob = {'terminals':{'NP':{'the':0.6,'an':0.3, '<unk>':0.1},\n",
    "                                                                      'ADJ':{'nice':0.6,'good':0.3,'<unk>':0.1},\n",
    "                                                                      'S':{'<unk>':0.01}}}\n",
    "                                                         'nonterminals':{'S':{'NP@VP':0.99}}\n",
    "    return:\n",
    "        score: dict() --- score[(i,i+span)][root] represents the highest score for the parse (sub)tree that has the root \"root\"\n",
    "                          across words w_i, w_{i+1},..., w_{i+span-1}.\n",
    "        back: dict() --- back[(i,i+span)][root] = (split , left_child, right_child); split: int; \n",
    "                         left_child: str; right_child: str. \n",
    "    '''\n",
    "    score = defaultdict(dict)\n",
    "    back = defaultdict(dict)\n",
    "    sent_len = len(sent)\n",
    "    ### YOUR CODE HERE\n",
    "\n",
    "\n",
    "    word_set = set()\n",
    "    for term in rules_prob['terminals'].keys():\n",
    "        for word in rules_prob['terminals'][term].keys():\n",
    "            word_set.add(word)\n",
    "\n",
    "    split = 0\n",
    "    for i in range(sent_len):\n",
    "      for term_key,term_val in rules_prob['terminals'].items():\n",
    "        if sent[i] in word_set and sent[i] in rules_prob['terminals'][term_key]:\n",
    "            score[(i,i+1)][term_key] = math.log(rules_prob['terminals'][term_key][sent[i]])\n",
    "            back[(i,i+1)][term_key] = (split,sent[i],None)\n",
    "        elif sent[i] in word_set and sent[i] not in rules_prob['terminals'][term_key]:\n",
    "          continue\n",
    "        else:\n",
    "          score[(i,i+1)][term_key] = math.log(rules_prob['terminals'][term_key]['<unk>'])\n",
    "          back[(i,i+1)][term_key] = (split,sent[i],None)\n",
    "    \n",
    "\n",
    "    for span in range(2,sent_len+1):\n",
    "      for begin in range(0,sent_len-span+1):\n",
    "        end=begin+span\n",
    "        for split in range(begin+1,end):\n",
    "          for nonterm_key in rules_prob['nonterminals'].keys():\n",
    "            for combined_child, probability in rules_prob['nonterminals'][nonterm_key].items():\n",
    "\n",
    "              left_child, right_child = combined_child.split('@')\n",
    "              left_childs = back[(begin,split)]\n",
    "              right_childs = back[(split,end)]\n",
    "          \n",
    "              if left_child in left_childs and right_child in right_childs:\n",
    "\n",
    "                if nonterm_key not in score[(begin,end)]:\n",
    "                  score[(begin,end)][nonterm_key] = math.log(probability) + score[(begin,split)][left_child]+ score[(split,end)][right_child]\n",
    "                  back[(begin,end)][nonterm_key] = (split,left_child,right_child)\n",
    "                else:\n",
    "                  temp = math.log(probability) + score[(begin,split)][left_child]+ score[(split,end)][right_child]\n",
    "                  if temp > score[(begin,end)][nonterm_key]:\n",
    "                      score[(begin,end)][nonterm_key] = temp\n",
    "                      back[(begin,end)][nonterm_key] = (split,left_child,right_child)\n",
    "\n",
    "\n",
    "\n",
    "    # word_set = set()\n",
    "    # for A in rules_prob['terminals'].keys():\n",
    "    #     for word in rules_prob['terminals'][A].keys():\n",
    "    #         word_set.add(word)\n",
    "            \n",
    "    # for i in range(sent_len):\n",
    "    #     #for A in non terminals\n",
    "    #     for A in rules_prob['terminals'].keys():\n",
    "    #         #check if word exists in rules\n",
    "    #         if sent[i] in word_set:\n",
    "    #             #if A -> sent[i] in rules we add it to the score and bp dict\n",
    "    #             if sent[i] in rules_prob['terminals'][A]:\n",
    "    #                 score[(i,i+1)][A] = math.log(rules_prob['terminals'][A][sent[i]])\n",
    "    #                 back[(i,i+1)][A] = (0,sent[i],None)\n",
    "    #         else:\n",
    "    #             #if word is unknown need to set for every terminal rule\n",
    "    #             score[(i,i+1)][A] = math.log(rules_prob['terminals'][A]['<unk>'])\n",
    "    #             back[(i,i+1)][A] = (0,sent[i],None)\n",
    "                \n",
    "    # for span in range(2,sent_len+1):\n",
    "    #     for begin in range(0,sent_len-span+1):\n",
    "    #         end = begin + span\n",
    "    #         for split in range(begin+1,end):\n",
    "    #             #for each split we need to rmb the best probability of each A\n",
    "    #             #for abc in non terminals\n",
    "    #             for A in rules_prob['nonterminals'].keys():\n",
    "    #                 for BC in rules_prob['nonterminals'][A].keys():\n",
    "    #                     B,C = BC.split('@')\n",
    "    #                     #check if B,C is in the tree with correct indices\n",
    "    #                     if B in back[(begin,split)] and C in back[(split,end)]:\n",
    "    #                         if A not in score[(begin,end)]:\n",
    "    #                             score[(begin,end)][A] = math.log(rules_prob['nonterminals'][A][BC]) + score[(begin,split)][B]+ score[(split,end)][C]\n",
    "    #                             back[(begin,end)][A] = (split,B,C)\n",
    "    #                         else:\n",
    "    #                             current_score = math.log(rules_prob['nonterminals'][A][BC]) + score[(begin,split)][B]+ score[(split,end)][C]\n",
    "    #                             if current_score > score[(begin,end)][A]:\n",
    "    #                                 score[(begin,end)][A] = current_score\n",
    "    #                                 back[(begin,end)][A] = (split,B,C)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ### END OF YOUR CODE                  \n",
    "    return score, back\n",
    "\n",
    "sent = cnf_train[0].leaves()\n",
    "score, back = CKY(sent, s_rules_prob)\n",
    "print(score[(0, len(sent))]['S'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qZrribRzWkiJ"
   },
   "outputs": [],
   "source": [
    "sent = cnf_train[0].leaves()\n",
    "score, back = CKY(sent, s_rules_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ntBprM7ZWkiL",
    "outputId": "a2797e32-5cef-405f-db77-31360b8ef093"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-117.52227496068694"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score[(0, len(sent))]['S']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Up5xHqJgWkiM"
   },
   "source": [
    "## Question 8\n",
    "Implement **build_tree** function according to algorithm 2 to reconstruct theparse tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ycSF2sutWkiN"
   },
   "outputs": [],
   "source": [
    "def build_tree(back, root,nonterminals):\n",
    "    '''\n",
    "    Build the tree recursively.\n",
    "    params:\n",
    "        back: dict() --- back[(i,i+span)][X] = (split , left_child, right_child); split:int; left_child: str; right_child: str.\n",
    "        root: tuple() --- (begin, end, nonterminal_symbol), e.g., (0, 10, 'S\n",
    "    return:\n",
    "        tree: nltk.tree.Tree\n",
    "    '''\n",
    "    begin = root[0]\n",
    "    end = root[1]\n",
    "    root_label = root[2]\n",
    "    ### YOUR CODE HERE\n",
    "    split, left_label, right_label = back[(begin, end)][root_label]\n",
    "    if split == 0: \n",
    "        tree = Tree(root_label, [left_label])\n",
    "    else:\n",
    "        left_child = build_tree(back, (begin, split, left_label), nonterminals)\n",
    "        right_child = build_tree(back, (split, end, right_label), nonterminals)\n",
    "        tree = Tree(root_label, [left_child, right_child])\n",
    "    ### END OF YOUR CODE \n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "colab_type": "code",
    "id": "u_N-QApGWkiP",
    "outputId": "4fc1d4a1-8175-4e57-902c-ce2055a9601e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP-SBJ\n",
      "    (NP (NNP pierre) (NNP vinken))\n",
      "    (NP-SBJ|<,-NP-,>\n",
      "      (, ,)\n",
      "      (NP-SBJ|<NP-,>\n",
      "        (NP (CD 61) (NP|<NNS-JJ> (NNS years) (JJ old)))\n",
      "        (, ,))))\n",
      "  (S|<VP-.>\n",
      "    (VP\n",
      "      (MD will)\n",
      "      (VP\n",
      "        (VB join)\n",
      "        (VP|<NP-PP-CLR-NP-TMP>\n",
      "          (NP (DT the) (NN board))\n",
      "          (VP|<PP-CLR-NP-TMP>\n",
      "            (PP-CLR\n",
      "              (IN as)\n",
      "              (NP\n",
      "                (DT a)\n",
      "                (NP|<JJ-NN> (JJ nonexecutive) (NN director))))\n",
      "            (NP-TMP (NNP nov.) (CD 29))))))\n",
      "    (. .)))\n"
     ]
    }
   ],
   "source": [
    "build_tree(back, (0, len(sent), 'S'), nonterminals).pprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pqtoQMosWkiR"
   },
   "source": [
    "## Question 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N23-J-zVWkiR"
   },
   "outputs": [],
   "source": [
    "def set_leave_index(tree):\n",
    "    '''\n",
    "    Label the leaves of the tree with indexes\n",
    "    Arg:\n",
    "        tree: original tree, nltk.tree.Tree\n",
    "    Return:\n",
    "        tree: preprocessed tree, nltk.tree.Tree\n",
    "    '''\n",
    "    for idx, _ in enumerate(tree.leaves()):\n",
    "        tree_location = tree.leaf_treeposition(idx)\n",
    "        non_terminal = tree[tree_location[:-1]]\n",
    "        non_terminal[0] = non_terminal[0] + \"_\" + str(idx)\n",
    "    return tree\n",
    "\n",
    "def get_nonterminal_bracket(tree):\n",
    "    '''\n",
    "    Obtain the constituent brackets of a tree\n",
    "    Arg:\n",
    "        tree: tree, nltk.tree.Tree\n",
    "    Return:\n",
    "        nonterminal_brackets: constituent brackets, set\n",
    "    '''\n",
    "    nonterminal_brackets = set()\n",
    "    for tr in tree.subtrees():\n",
    "        label = tr.label()\n",
    "        #print(tr.leaves())\n",
    "        if len(tr.leaves()) == 0:\n",
    "            continue\n",
    "        start = tr.leaves()[0].split('_')[-1]\n",
    "        end = tr.leaves()[-1].split('_')[-1]\n",
    "        if start != end:\n",
    "            nonterminal_brackets.add(label+'-('+start+':'+end+')')\n",
    "    return nonterminal_brackets\n",
    "\n",
    "def word2lower(w, terminals):\n",
    "    '''\n",
    "    Map an unknow word to \"unk\"\n",
    "    '''\n",
    "    return w.lower() if w in terminals else '<unk>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 867
    },
    "colab_type": "code",
    "id": "4JMIAjcpWkiT",
    "outputId": "24b8941c-7ba2-4fff-a894-8117abe7745e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\n",
      "Test Tree: 1\n",
      "Constituent number in the predicted tree: 20\n",
      "Constituent number in the gold tree: 20\n",
      "Correct constituent number: 14\n",
      "####################\n",
      "Test Tree: 2\n",
      "Constituent number in the predicted tree: 54\n",
      "Constituent number in the gold tree: 54\n",
      "Correct constituent number: 28\n",
      "####################\n",
      "Test Tree: 3\n",
      "Constituent number in the predicted tree: 30\n",
      "Constituent number in the gold tree: 30\n",
      "Correct constituent number: 23\n",
      "####################\n",
      "Test Tree: 4\n",
      "Constituent number in the predicted tree: 17\n",
      "Constituent number in the gold tree: 17\n",
      "Correct constituent number: 16\n",
      "####################\n",
      "Test Tree: 5\n",
      "Constituent number in the predicted tree: 32\n",
      "Constituent number in the gold tree: 32\n",
      "Correct constituent number: 26\n",
      "####################\n",
      "Test Tree: 6\n",
      "Constituent number in the predicted tree: 40\n",
      "Constituent number in the gold tree: 40\n",
      "Correct constituent number: 18\n",
      "####################\n",
      "Test Tree: 7\n",
      "Constituent number in the predicted tree: 22\n",
      "Constituent number in the gold tree: 22\n",
      "Correct constituent number: 7\n",
      "####################\n",
      "Test Tree: 8\n",
      "Constituent number in the predicted tree: 18\n",
      "Constituent number in the gold tree: 18\n",
      "Correct constituent number: 6\n",
      "####################\n",
      "Test Tree: 9\n",
      "Constituent number in the predicted tree: 28\n",
      "Constituent number in the gold tree: 28\n",
      "Correct constituent number: 16\n",
      "####################\n",
      "Test Tree: 10\n",
      "Constituent number in the predicted tree: 40\n",
      "Constituent number in the gold tree: 40\n",
      "Correct constituent number: 8\n"
     ]
    }
   ],
   "source": [
    "correct_count = 0\n",
    "pred_count = 0\n",
    "gold_count = 0\n",
    "for i, t in enumerate(cnf_test):\n",
    "    #Protect the original tree \n",
    "    t = copy.deepcopy(t)\n",
    "    sent = t.leaves()  \n",
    "    #Map the unknow words to \"unk\"\n",
    "    sent = [word2lower(w.lower(), terminals) for w in sent]\n",
    "    \n",
    "    #CKY algorithm\n",
    "    score, back = CKY(sent, s_rules_prob)\n",
    "    candidate_tree = build_tree(back, (0, len(sent), 'S'), nonterminals)\n",
    "    \n",
    "    #Extract constituents from the gold tree and predicted tree\n",
    "    pred_tree = set_leave_index(candidate_tree)\n",
    "    pred_brackets = get_nonterminal_bracket(pred_tree)\n",
    "    \n",
    "    #Count correct constituents\n",
    "    pred_count += len(pred_brackets)\n",
    "    gold_tree = set_leave_index(t)\n",
    "    gold_brackets = get_nonterminal_bracket(gold_tree)\n",
    "    gold_count += len(gold_brackets)\n",
    "    current_correct_num = len(pred_brackets.intersection(gold_brackets))\n",
    "    correct_count += current_correct_num\n",
    "    \n",
    "    print('#'*20)\n",
    "    print('Test Tree:', i+1)\n",
    "    print('Constituent number in the predicted tree:', len(pred_brackets))\n",
    "    print('Constituent number in the gold tree:', len(gold_brackets))\n",
    "    print('Correct constituent number:', current_correct_num)\n",
    "\n",
    "recall = correct_count/gold_count\n",
    "precision = correct_count/pred_count\n",
    "f1 = 2*recall*precision/(recall+precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "zJZdy3nsWkiU",
    "outputId": "3ad3165e-4d94-4347-b157-26b2f92fa33a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall precision: 0.538, recall: 0.538, f1: 0.538\n"
     ]
    }
   ],
   "source": [
    "print('Overall precision: {:.3f}, recall: {:.3f}, f1: {:.3f}'.format(precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "zlrkpetrWkiW",
    "outputId": "36601e4b-da69-4517-9a7d-a1b35e240ee0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall precision: 0.538, recall: 0.538, f1: 0.538\n"
     ]
    }
   ],
   "source": [
    "print('Overall precision: {:.3f}, recall: {:.3f}, f1: {:.3f}'.format(precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "JlEHs_hAWkiX",
    "outputId": "acad5020-3ce0-40ec-e6e8-edbe98ffa63b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "841.3007383346558\n"
     ]
    }
   ],
   "source": [
    "et=time.time()\n",
    "print(et - st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sYQ-nVXQzU_P"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "homework2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
